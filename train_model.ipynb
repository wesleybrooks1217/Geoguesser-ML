{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'pictures'\n",
    "test_dir = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    img_label = img.split('.')[0]\n",
    "    return img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    imgs = np.empty((20000,300,20,3))\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    for img in tqdm(os.listdir(train_dir)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(train_dir,img)\n",
    "        img = cv2.imread(path)\n",
    "        img = np.array(img)/255\n",
    "        img = apply_pca(img)\n",
    "        imgs[counter] = img\n",
    "        labels.append(label)\n",
    "        counter+=1\n",
    "    return imgs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    imgs = np.empty((20000,300,20,3))\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    for img in tqdm(os.listdir(test_dir)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(test_dir,img)\n",
    "        img = cv2.imread(path)\n",
    "        img = np.array(img)/255\n",
    "        img = apply_pca(img)\n",
    "        imgs[counter] = img\n",
    "        labels.append(label)\n",
    "        counter+=1\n",
    "    return imgs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(img):\n",
    "    pca = PCA(20)\n",
    "    #apply pca\n",
    "    blue= np.squeeze(img[:,:,0])\n",
    "    green = np.squeeze(img[:,:,1])\n",
    "    red = np.squeeze(img[:,:,2])\n",
    "    red_transformed = pca.fit_transform(red)\n",
    "    #Applying to Green channel and then applying inverse transform to transformed array.\n",
    "    green_transformed = pca.fit_transform(green)\n",
    "    #Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "    blue_transformed = pca.fit_transform(blue)\n",
    "    img = np.stack((red_transformed, green_transformed, blue_transformed), axis = 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_pca(x):\n",
    "#     pca = PCA(50)\n",
    "#     pca_x = [None] * len(x)\n",
    "#     for i in tqdm(range(len(x))):\n",
    "#         #apply pca\n",
    "#         img = x[i]\n",
    "#         blue= np.squeeze(img[:,:,0])\n",
    "#         green = np.squeeze(img[:,:,1])\n",
    "#         red = np.squeeze(img[:,:,2])\n",
    "#         red_transformed = pca.fit_transform(red)\n",
    "#         #Applying to Green channel and then applying inverse transform to transformed array.\n",
    "#         green_transformed = pca.fit_transform(green)\n",
    "#         #Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "#         blue_transformed = pca.fit_transform(blue)\n",
    "#         img = np.stack((red_transformed, green_transformed, blue_transformed), axis = 2).tolist()\n",
    "#         pca_x[i] = (img)\n",
    "#     return pca_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20000/20000 [12:43<00:00, 26.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 300, 20, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = create_train_data()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_20.npy', 'rb') as f:\n",
    "    x = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "...        ...\n",
       "19995        9\n",
       "19996        9\n",
       "19997        9\n",
       "19998        9\n",
       "19999        9\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_df = pd.DataFrame({'Country': y})\n",
    "labelencoder = LabelEncoder()\n",
    "country_df['Country'] = labelencoder.fit_transform(country_df['Country'])\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02218279e+00, -4.84941189e-01, -2.41022031e+00],\n",
       "       [-9.31612531e-01, -5.84405166e-01, -3.12575206e-01],\n",
       "       [ 2.08270487e-01, -2.01310804e-01, -1.78737620e-01],\n",
       "       [ 1.05329410e-01,  3.87763808e-01, -1.01444098e-01],\n",
       "       [ 9.78887471e-02, -5.02803127e-02, -3.81730058e-02],\n",
       "       [-1.46627036e-02,  1.33104733e-01, -6.50532819e-02],\n",
       "       [-1.71998721e-02, -1.79898547e-01,  2.87050094e-02],\n",
       "       [ 4.18145208e-02,  2.00201091e-02, -7.77057712e-02],\n",
       "       [-5.40797810e-02, -7.21349337e-02,  9.55145637e-02],\n",
       "       [-2.72220738e-04,  1.08720753e-01,  1.33329190e-01],\n",
       "       [-7.54291534e-02, -1.41987138e-01, -2.51653967e-02],\n",
       "       [ 7.68809297e-02, -4.90614934e-04, -1.68306446e-01],\n",
       "       [ 7.89092957e-02, -9.08037558e-02, -1.22106484e-02],\n",
       "       [ 2.39034213e-02,  3.03164672e-02,  8.60105706e-02],\n",
       "       [-5.47912851e-02, -1.31611990e-02, -5.63997254e-02],\n",
       "       [ 4.04125169e-02,  3.37068588e-02, -1.73724475e-02],\n",
       "       [ 7.01573263e-02,  1.60954765e-02, -1.04588682e-01],\n",
       "       [ 2.20072184e-02, -6.46715865e-02,  1.60155063e-01],\n",
       "       [ 1.29819095e-01, -5.12415311e-02,  5.59765924e-03],\n",
       "       [ 6.72278902e-02, -4.05298473e-03, -9.42453138e-03]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    " \n",
    "    def __init__(self,x,y):\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float64)\n",
    "        self.x_train = torch.reshape((self.x_train), (len(self.x_train), 3, 300, 20))\n",
    "        self.y_train=torch.tensor(y,dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = country_df[\"Country\"]\n",
    "md = MyDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(\n",
    "    md,\n",
    "    batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,300,20)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.fc= nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64 * 75 * 5, num_classes))\n",
    "    def forward(self, input):\n",
    "        out = self.layer1(input.float())\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckp_path = \"best_checkpoint.model\"\n",
    "checkpoint = torch.load(ckp_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(0.4923) Train Accuracy: 0.8302\n",
      "Epoch: 1 Train Loss: tensor(0.4598) Train Accuracy: 0.8406\n",
      "Epoch: 2 Train Loss: tensor(0.4510) Train Accuracy: 0.8426\n",
      "Epoch: 3 Train Loss: tensor(0.4466) Train Accuracy: 0.84665\n",
      "Epoch: 4 Train Loss: tensor(0.4215) Train Accuracy: 0.85095\n",
      "Epoch: 5 Train Loss: tensor(0.4121) Train Accuracy: 0.85665\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "train_count = 20000\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "    \n",
    "    torch.save(model.state_dict(),'best_checkpoint.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 25.91it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test,y_test = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARG' 'AUS,' 'GBR' 'ISR' 'JPN' 'KEN' 'PRT' 'RUS' 'USA' 'ZAF']\n"
     ]
    }
   ],
   "source": [
    "country_df = pd.DataFrame({'Country': y_test})\n",
    "print(country_df[\"Country\"].unique())\n",
    "labelencoder = LabelEncoder()\n",
    "country_df['Country_label'] = labelencoder.fit_transform(country_df['Country'])\n",
    "y_test = country_df[\"Country_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snivy\\AppData\\Local\\Temp\\ipykernel_10652\\4113779628.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  self.x_train=torch.tensor(x,dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mdt = MyDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=DataLoader(\n",
    "    mdt,\n",
    "    batch_size=500, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.44186047, 0.09375   , 0.22807018, 0.375     , 0.47619048,\n",
      "       0.53191489, 0.53658537, 0.21052632, 0.1969697 , 0.41304348]), array([0.38, 0.06, 0.26, 0.36, 0.6 , 0.5 , 0.44, 0.24, 0.26, 0.38]), array([0.40860215, 0.07317073, 0.24299065, 0.36734694, 0.53097345,\n",
      "       0.51546392, 0.48351648, 0.22429907, 0.22413793, 0.39583333]), array([50, 50, 50, 50, 50, 50, 50, 50, 50, 50], dtype=int64))\n",
      "[[19  4  5  4  2  3  2  4  3  4]\n",
      " [ 6  3  9  4  7  2  1  5 12  1]\n",
      " [ 2  4 13  5  2  2  3 10  4  5]\n",
      " [ 3  2  4 18  2  2  5  3  4  7]\n",
      " [ 1  0  2  4 30  1  2  4  4  2]\n",
      " [ 1  2  2  0  4 25  1  1  9  5]\n",
      " [ 1  1  7  2  2  3 22  8  4  0]\n",
      " [ 5  6  8  3  5  2  3 12  5  1]\n",
      " [ 3  7  5  4  7  2  2  5 13  2]\n",
      " [ 2  3  2  4  2  5  0  5  8 19]]\n",
      "Test Accuracay: 0.348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_accuracy = 0\n",
    "recall = 0\n",
    "precision = 0\n",
    "test_count = 500\n",
    "for i, (images,labels) in enumerate(test_loader):\n",
    "    if torch.cuda.is_available():\n",
    "        images=Variable(images.cuda())\n",
    "        labels=Variable(labels.cuda())\n",
    "\n",
    "    outputs=model(images)\n",
    "    _,prediction=torch.max(outputs.data,1)\n",
    "    test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    print(precision_recall_fscore_support(labels.data, prediction, average = None, labels = range(10)))\n",
    "    print(confusion_matrix(labels.data, prediction))\n",
    "test_accuracy=test_accuracy/test_count\n",
    "print(\"Test Accuracay: \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([5, 0, 5, 3, 7, 5, 2, 2, 3, 0, 1, 0, 7, 6, 7, 6, 4, 8, 9, 7, 5, 4, 5, 2,\n",
      "        3, 5, 9, 9, 5, 4, 3, 6, 4, 9, 2, 2, 8, 9, 7, 0, 2, 3, 3, 5, 8, 5, 2, 4,\n",
      "        1, 4, 7, 3, 5, 7, 4, 9, 6, 6, 4, 4, 7, 2, 7, 0, 2, 5, 9, 8, 9, 3, 8, 9,\n",
      "        2, 3, 7, 7, 5, 3, 3, 7, 8, 5, 9, 3, 2, 9, 9, 9, 7, 8, 8, 5, 7, 4, 4, 5,\n",
      "        0, 0, 9, 3, 2, 9, 2, 7, 2, 2, 9, 6, 4, 9, 9, 3, 3, 2, 7, 9, 9, 3, 6, 0,\n",
      "        7, 6, 9, 2, 8, 2, 3, 9, 4, 4, 3, 8, 7, 9, 0, 9, 7, 4, 4, 6, 0, 8, 9, 4,\n",
      "        1, 5, 2, 5, 0, 2, 2, 8, 7, 7, 0, 0, 9, 8, 7, 0, 7, 4, 9, 0, 4, 5, 9, 3,\n",
      "        9, 4, 8, 4, 9, 9, 4, 5, 4, 5, 4, 2, 1, 9, 9, 0, 8, 2, 3, 3, 8, 6, 9, 8,\n",
      "        7, 8, 0, 0, 4, 2, 4, 7, 6, 5, 5, 0, 2, 4, 4, 4, 9, 0, 5, 9, 5, 9, 6, 2,\n",
      "        8, 6, 3, 6, 7, 5, 6, 0, 7, 2, 9, 8, 9, 7, 4, 2, 4, 2, 3, 5, 8, 1, 3, 4,\n",
      "        8, 3, 3, 2, 4, 9, 9, 4, 4, 1, 4, 2, 4, 9, 3, 4, 0, 7, 5, 2, 4, 2, 6, 3,\n",
      "        4, 9, 2, 1, 5, 9, 9, 4, 7, 0, 3, 5, 7, 9, 6, 4, 8, 8, 0, 0, 4, 9, 7, 5,\n",
      "        6, 6, 7, 3, 4, 7, 5, 6, 3, 0, 1, 2, 9, 1, 5, 4, 5, 9, 3, 7, 2, 0, 4, 7,\n",
      "        6, 4, 9, 0, 3, 9, 4, 2, 4, 9, 4, 1, 4, 4, 5, 8, 9, 4, 9, 7, 5, 6, 5, 5,\n",
      "        8, 5, 2, 8, 6, 7, 3, 7, 6, 2, 8, 9, 5, 1, 1, 8, 9, 6, 8, 9, 3, 1, 3, 9,\n",
      "        9, 3, 8, 9, 9, 7, 5, 3, 2, 6, 0, 1, 0, 7, 9, 7, 4, 2, 9, 6, 3, 0, 4, 3,\n",
      "        4, 7, 4, 7, 8, 3, 0, 7, 2, 0, 4, 7, 0, 7, 0, 9, 9, 3, 7, 6, 8, 4, 2, 6,\n",
      "        7, 1, 7, 0, 0, 7, 5, 4, 0, 5, 6, 4, 2, 8, 4, 2, 8, 8, 4, 4, 4, 4, 1, 3,\n",
      "        9, 8, 9, 8, 7, 0, 2, 8, 1, 0, 4, 9, 8, 2, 4, 5, 4, 6, 9, 7, 9, 4, 7, 4,\n",
      "        9, 2, 2, 1, 2, 4, 2, 4, 3, 1, 9, 4, 1, 7, 7, 2, 6, 9, 0, 0, 0, 5, 7, 9,\n",
      "        6, 6, 9, 0, 7, 7, 2, 3, 3, 4, 9, 6, 5, 4, 8, 2, 4, 3, 7, 6])]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "495    9\n",
      "496    9\n",
      "497    9\n",
      "498    9\n",
      "499    9\n",
      "Name: Country_label, Length: 500, dtype: int32\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "186cb387e042da14a9b62a898b14b1784972969edcbe8cc2ad7cf02e92176225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
